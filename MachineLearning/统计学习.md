### 1.3 统计学习的三要素
统计学习方法 = 模型 + 策略 + 算法
1. 模型：描述输入与输出随机变量之间的映射关系，可以是概率模型或非概率模型，由条件概率分布P(Y|X)或决策函数Y=f(X)表示。模型的假设空间包含所有可能的条件概率分布或决策函数的集合：由一个参数向量决定的函数族或条件概率分布族，其中参数向量取之于n维欧式空间$R^n$。
2. 策略：损失函数（代价函数）L(Y,f(X))度量一次预测的好坏，风险函数（期望损失）度量平均意义下的好坏。损失函数：0-1损失函数、平方损失函数、绝对损失函数、对数损失函数（对数似然损失函数）。风险函数：模型输入输出(X,Y)是随机变量，遵循联合分布P(X,Y)，模型f(X)关于联合分布P(X,Y)的平均意义下的损失就是风险函数，其中联合分布是未知的。经验风险：训练数据集的平均损失。N无穷大时，经验风险趋近于期望风险。对经验风险进行矫正来近似期望风险，认为经验风险最小化的模型就是最优的模型。模型是条件概率分布，损失函数是对数损失函数，那么经验风险最小化就等同于极大似然估计。结构风险最小化是经验风险加上正则化项，正则化系数lambda用于权衡经验风险和模型复杂度。监督学习问题成了经验风险或结构风险函数的最优化问题，这时的经验和结构风险函数是最优化的目标函数。
3. 算法：学习模型的计算方法，最优化问题没有解析解，这就需要用数值计算的方法求解。问题：如何保证找到全局最优解，并使得求解的过程非常高效。

### 1.4 模型评估与模型选择
1. 训练误差与测试误差

 选择测试误差小的模型

学习方法对未知数据的预测能力成为泛化能力

2. 过拟合与模型选择
模型选择时，不仅要考虑模型对已知数据的预测能力，还要考虑对未知数据的拟合能力，使得测试误差较小。

### 1.5 正则化和交叉验证
模型选择的两种方法

1. 正则化
符合奥卡姆剃刀（Occam's razor）原理，简单的才是最好的。
2. 交叉验证
样本数据充足的情况下，将数据集划分为3个部分：训练集（训练模型）、验证集（模型的选择）、测试集（学习方法的评估）。选择对验证集有最小预测误差的模型。

在样本数据不充分的情况下，采用交叉验证的方法。

S折交叉验证：将数据集划分为大小相同互不相交的子集，S-1作为训练集，余下作为测试集测试模型。S次实验后选择平均测试误差最小的模型。
